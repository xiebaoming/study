---
typora-copy-images-to: ..\img
---

# 思维导图

![](../img/computednetwork.awebp)

# 一、OSI 七层体系结构*

## 应用层：

> HTTP(超文本传输协议)：规定web服务端和客户端的数据传输格式
>
> DNS（域名解析协议）将域名解析为IP地址
>
> FTP(文件传输协议)：网络共享文件传输
>
> SMTP（简单邮件传输协议）：从发送方的邮件服务器向接收方的邮件服务器发送邮件。一般不使用中间邮件服务器发送邮件相连。
>
> TELNET：使用远程计算机上所拥有的本地计算机没有的信息资源，是常用的远程控制Web服务器的方法

应用层负责为操作系统或网络应用程序提供访问网络服务的端口，定义了信息交换的格式，消息会交给传输层来传输。

![1649840988004](../img/1649840988004.png)

## 表示层：

> ASCII、SSL/TLS

表示层是确保一个系统的应用层发送的消息可以被另外一个系统的应用层读取，并处理用户信息的表示问题，如编码、数据格式转换和加密解密等。

## 会话层：

> ADSP、RPC

会话层则通过传输层建立数据传输的通道，在系统之间发起会话或者接受会话请求，并组织和协调两个会话进程之间的通信，对数据交换进行管理。

## 传输层：

> TCP、UDP

传输层则在网络层的基础上，为应用进程之间的通信提供通用的数据传输服务。根据用户需求，传输层有两种不同的传输协议，分别是面向连接的TCP协议和面向无连接的UDP协议。

## 网络层：

> ARP地址解析协议，ICMP网际报文控制协议，路由选择协议：RIP、OSPF、BGP

网络层向其上层只提供简单灵活的，无连接的，尽最大努力交付的数据报服务。在发送数据时，网络层把传输层产生的（TCP）**报文段**或（UDP）**用户数据报**封装成**IP数据报**进行传送。网络层还有一个任务就是通过路由选择协议选择合适的路由，使源主机传输层所传下来的分组，能通过网络层中的路由器找到目的主机。

> 我们可以把**网络接口层**看作是数据链路层和物理层的合体

## 数据链路层：

> PPP、SLIP、HDLC

数据链路层则进行封装成帧，透明传输和差错检验，封装成帧是在网络层传递下来的IP数据报加上头部和尾部，透明传输是不管从键盘上输入什么字符都可以放在帧的数据部分然后传输过去。这其中使用了字节填充来解决帧的数据部分可能会出现控制字符的问题。差错检验是采用CRC循环冗余码来检测传输差错。

## 物理层：

物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，尽可能屏蔽掉传输介质和物理设备的差异。



## 为什么要对网络协议分层

1首先是为了保证各层之间的独立性，某一层可以使用下一层提供的服务而不需要知道其具体实现。

2.然后是灵活性好。当某一层出现技术革新或者出现问题时，只要层间接口关系保持不变，则其余各层均不受影响。排除问题时也只需要考虑这一层单独的问题即可。

3.还有易于调试和维护。进行调试和维护时，可以对每一层进行单独的调试。

4.最后是能促进标准化工作。标准化的好处就是可以随意替换其中的某一层，对于使用和科研来说十分方便。



OSI和TCP/IP ？？？？？？

TCP/IP 与 OSI 在分层模块上稍有区别。OSI 参考模型注重“通信协议必要的功能是什么”，而 TCP/IP 则更强调“在计算机上实现协议应该开发哪种程序”。

# 二、网络层

## IP地址和MAC地址

**答：**MAC地址是固化在网络适配器上的硬件地址，也叫物理地址，使用它来定义网络设备的位置；MAC地址是数据链路层和物理层使用的地址，主要由数据链路层负责；

而 IP 地址是 IP 协议提供的一种统一的地址格式，是为互联网上的每一个网络和每一台主机分配的一个逻辑地址，**以此来屏蔽物理地址的差异**；

![1661501490327](../img/1661501490327.png)

（mac地址在同一个广播域传输过程中是不变的，在跨越广播域的时候会发生改变的；而IP地址在传输过程中是不会改变的）

## ARP地址解析协议

IP地址是网络层及其上层使用的地址，也就是说数据链路层和物理层IP地址是不可见的，这时候就需要按照MAC地址来进行数据转发，使用的是ARP地址解析协议。ARP地址解析协议解决的是**同一个局域网**上的主机和路由器的IP地址到MAC地址的映射问题。

每一台主机都设有一个ARP高速缓存，里面存有本局域网上的各个主机和路由器的IP地址到MAC地址的映射表。

ARP协议是借助ARP请求和ARP响应两种类型的包来确定MAC地址的，然后缓存在这个映射表中。

1.首先主机会通过广播发送ARP请求，这个包中包含了想要知道MAC地址的IP地址

2.当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包中的内容，如果ARP请求包的目标IP地址和自己的IP地址一致，那么这个设备就将自己的MAC地址塞入到ARP响应包返回给主机

![](../img/rip.awebp)



问：为什么不直接用MAC地址进行通讯？

**答：**由于全世界存在着各式各样的网络，它们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，因此几乎是不可能的事

而连接到 Internet 的主机都拥有统一的IP地址，它们之间的通信就像连接在同一个网络上那样简单方便，因为使用ARP协议来寻找某个路由器或主机的硬件地址都是由计算机软件自动进行的，对用户来说看不见这种调用过程



## 最大传输单元 ( MTU ) 和最大报文段长度 ( MSS )

MTU（Maximum Transmit Unit）：是数据链路层提供给网络层最大一次传输数据的大小。以太网的数据链路层最大传输单元MTU是1500字节，当 IP 数据报大于1500字节时，IP数据报就会被分片，经过分片后的IP数据报在重组的时候只能由目标主机进行，路由器是不会进行重组的。在分片传输过程中，一旦某个分片丢失，则会造成整个IP数据报作废，所以TCP引入了MSS也就是为了进行TCP分段而不是进行IP分片，MSS是TCP用来限制应用层最大的发送字节数。而对于UDP我们尽量不要传输一个大于MTU的数据报文。如果MTU= 1500 byte，则 MSS = 1500- IP数据报头部的20字节-TCP头部的20 = 1460 byte，如果应用层有2000 byte发送，需要两个段才可以完成发送，第一个TCP 段 = 1460，第二个TCP 段 = 540

> 在TCP三次握手中前2次握手的syn报文的"选项"字段中会有MSS值，用于协商双方的mss值。



22.IPv4和IPv6差别

> IPV4:192.168.0.1   （8*4）
>
> IPV6：2001:cdba:0000:0000:0000:0000:3257:9652   （16*8）

**答：**1.更大的地址空间：IPv4是32位的，IPv6是128位的，扩大了4倍。IPv4总共有四组，每组有8位，采用点分十进制的方式表示；IPv6总共有8组，每组有16位，采用16进制表示。

2.IPV6支持即插即用（自动配置）功能；即使没有DHCP服务器也能够自动分配IP地址

3.性能提升（从数据包首部字段方面看）

1). 包首部长度采用固定的40个字节来表示，**不再采用首部校验码**；简化首部结构，减轻路由负荷

2). 路由器不再做分片处理，数据包分片只能由发送端进行；取消分片后，IPV6首部**不再有数据包标识以及标志和片偏移等字段**

3). **取消选项字段**，选项字段不再是标准IP首部的一部分，但它并没有消失，取而代之的是使用扩展首部，当需要对数据报分片时，可以使用扩展首部；IPV4的选项长度最大只能为40字节，但是IPV6的扩展首部长度可以是任意长度 ，没有具体的大小限制  （图解TCP/IP P154）

附：IPv4和IPv6不能互相兼容，所以不但要我们电脑，手机之类的设备支持，还需要网络运营商对现有的设备进行升级，这可能是IPv6普及比较慢的原因



**关于NAT:**

内网IP想要与外网通信需要使用NAT地址转换技术，把**私有IP**地址转换成**公有IP地址**。NAT的使用是为了解决公网IP有限及局域网安全性的问题。

路由器利用 NAT(Network Address Translation)，将你的主机IP（局域网IP）转换为外网IP，还会修改端口号，对外完全隐藏你的主机，再根据路由表选择一条合适的路径进行转发

NAT是一种网络隐蔽技术，它通过建立IP地址映射来隐藏内部的网络
它的主要功能有：

- 提高内部网络的安全性
- 共享网络地址，减少地址消耗

NAT主要有三种实现方式：

- 静态NAT（Basic NAT）：最基本的网络转换实现，只转换IP地址，建立IP地址的一对一映射，不支持端口转换
- 网络地址端口转换（NAPT）：这种方式支持端口的映射，并允许多台主机共享一个公网IP地址
- 端口多路复用（Port address Translation,PAT)：是指改变外出数据包的源端口并进行端口转换，即端口地址转换.采用端口多路复用方式。


> NAT穿透：
>
> 对等网络传输需穿透NAT：IP协议的定义中，在理论上，具有IP地址的每个站点在协议层面有相当的获取服务和提供服务的能力，不同的IP地址之间没有差异。但NAT工作原理破坏了这个特征，如需实现真正意义上的对等网络传输，则需要穿透NAT。


## 各层协议

### ICMP

ICMP ( 网际报文控制 )协议属于**网络层**，这是因为ICMP报文装在IP数据报中，作为其中的数据部分。

它的功能主要包括：确认IP数据报是否成功送达目标地址，以及报告发送过程中的IP包被废弃的原因和改善网络设置等，有了这些功能以后，就可以获得网络是否正常，设置是否有误以及设备有何异常等信息，从而便于进行网络上的问题诊断。在IP通信中如果某个IP包因为某种原因未能到达目标地址，那么这个具体的原因将由 ICMP 负责通知。PING是最常用的基于ICMP的服务。

ICMP有2种类型的报文：ICMP差错报告报文和ICMP询问报文。

比如：

ping命令用到的：类型为8 的回送请求(Echo Request)  	类型为0的回送应答 (Echo Replay)

类型为3的不可到达，类型为5的改变路由，还有traceroute命令用到的类型为11 的超时



**Ping工作流程：**

ping命令主要利用的是 ICMP 里面的类型为8的回送请求和类型为0回送回答的两种消息。

主机A ping 主机B时，主机A会发送一个ICMP回送请求的数据包，大小为32位。

主机 B 如果正常收到请求报文后，会构建一个ICMP回送回答消息数据包，该数据包的类型字段为0，序号为接收到的请求数据包中的序号，然后再发送给主机A。

如果不能正常接收，由中途的路由器返回数据包不能到达的原因



**traceroute工作流程：**

作用一：故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器数，它的原理就是发送TTL数值从１逐渐增大的UDP用户数据报，直到返回正确的响应报文就可以知道目标主机离我们有多少个路由器了。TTL每经过一个路由器就会减1，减到0就会将数据报丢弃，并向源主机发送一个ICMP时间超过差错报告报文。

作用二：故意设置不分片，用来确定路径的MTU，因为有的时候我们并不知道路由器的MTU大小，以太网的数据链路层的MTU通常是1500字节，但是非以太网的MTU就不一样了， 所以我们要知道MTU的大小，从而控制包的大小



**当路由器接收到的IP报文的TTL的值为1时，采取的策略为？**

**答：**经过该路由器TTL的值就变成0了，所以路由器会丢掉该数据包。并向源主机发送一个ICMP时间超过差错报告报文。

附：不同系统的TTL值

Linux和Unix是64     Windows是128     Solaris是254



### 路由选择协议

>  内部网关协议：RIP, OSPF，外部网关协议：BGP

#### **RIP**

RIP路由信息协议规定，路由器每隔 30s 就与相邻的路由器交换信息，交换的信息是路由器现在的路由表。**RIP协议选择最佳路径的标准是跳数**，认为到达目标网络经过路由器最少的路径就是最佳路径，默认其所允许的最大跳数为15跳，也就是说16跳的距离会被认为是不可到达的，所以RIP协议只适用于小型网络。因为只有相邻路由器交换信息，所以RIP网络的收敛速度非常的慢，而且会占用大量带宽。

距离向量算法：

- 对地址为X的相邻路由器发来的RIP报文，先将该报文的“下一跳”字段中的地址都改为X，并把跳数加1。
- 对RIP报文的每一行数据进行：
  - 若原来路由表没有，则添加该行数据
  - 有的话，查看下一跳地址
    - 如果地址是x则替换
    - 地址不是x则进行更新，取跳数小的

#### OSPF

OSPF开放最短路径优先协议克服了RIP的缺点。OSPF开放最短路径优先协议规定：路由器向本自治系统中的所有路由器发送信息，这种方法是洪泛法。发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。当链路状态发生变化或每隔30秒，路由器就会发送信息。所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。

工作过程：

用hello分组来寻找邻居，并建立邻接关系。然后进行链路状态信息传递，过程是先使用数据库描述分组（database description）和相邻路由器交换本数据库中已有的链路状态信息，交换信息后再用链路状态请求（link state request）向对方请求自己所缺少的某些链路状态项目的详细信息。通过一系列的这种分组交换，全网同步的链路数据库就建立好了。

#### BGP

BGP (Border Gateway Protocol) 边界网关协议。用于处理各ISP之间的路由传递。主要用于互联网AS（自治系统）之间的互联。

边界路由器之间建立完TCP连接后互相发送可达信息，然后边界路由器再将信息转发给AS内部的路由器。



## 网络设备

### 集线器

集线器是**物理层**扩展以太网的设备，相当于多端口的中继器 ，将主机互联形成局域网。使用集线器作为互连设备的以太网仍然属于共享总线式以太网。集线器互连起来的所有主机共享总线带宽，**属于同一个碰撞域和广播域。** 在扩大了广播域的同时也扩大了碰撞域。

![1650174600882](../img/1650174600882.png)



注：而交换机扩大了广播域的同时隔离了碰撞域

![1650174730117](../img/1650174730117.png)

### 交换机

> 网桥可以理解为**两个网线口的交换机**，正好可以把两台电脑给连起来，也叫**桥接**。而交换机，则是**多网线口的网桥**，可以把多台电脑给连（桥接）起来，可以使多对主机同时通信，无碰撞的传输数据。问网桥答交换机功能。

交换机是基于以太网设计的，位于数据链路层，俗称⼆层网络设备，交换机的端口不具有 MAC 地址，通常用于同一网段内的主机之间通信。

交换机依靠MAC地址进行**转发**和**过滤**。交换机内有一张**MAC表**，里面存放着和它相连的所有设备的MAC地址和端口号的映射，它会根据收到的**数据帧**的**首部信息内**的目的MAC地址在自己的表中查找，如果有就转发，没有就把它丢弃（也就是过滤）。在发送包的时候，会将发送MAC地址和相应的端口号和写入表中，因为从这个端口发的大概率也是从这个端口接受的。

考虑到有时可能要在交换机的端口更改主机，或者主机更换其网络适配器会修改主机MAC地址，这就需要及时更改交换表中的项目，因此每次写入一个项目时就记下当前时间，超过预期设定的时间后项目就会自动删除。

![1649899096539](../img/1649899096539.png)

### **虚拟局域网**

因为以太网交换机的问世，一个以太网交换机可以非常方便地连接十几台计算机，构成一个星型以太网。

但是一个以太网包含的计算机太多，会带来一些问题。

- 首先是安全性问题，比如一个单位的以太网中，有些部门的信息是想要保密的
- 其次是一个以太网是一个广播域，这时候传播广播帧的时候必然会消耗更多的网络资源，如果配置出错了还可能发生广播帧在网络无限制兜圈子，使网络瘫痪。

这时候就需要用交换机来建立虚拟局域网VLAN（virtual LAN），把大的局域网分割一些较小的局域网，每一个局域网是一个较小的广播帧，划分虚拟局域网可以使用交换机的端口划分，也可以按照主机MAC地址划分。

虚拟局域网是给用户提供的一种服务，并不是一种新型局域网，实现方式是使用栈格式中的VLAN标签，也就是一个4字节的标识符来指明该帧的计算机属于哪一个局域网。

VLAN的作用有以下几点：

1.限制广播域：广播域限制在一个 VLAN 中，节省了带宽，提高了网路的处理能力

2.增强局域网的安全性：不同 VLAN 内的报文在传输时是相互隔离的，即一个 VLAN 内的用户不能和其他VLAN内的用户直接通信

3.提高网络的健壮性：故障被限制在一个 VLAN 中，本 VLAN 中的故障不会影响到其他 VLAN 的正常工作

4.灵活构建虚拟工作组：用 VLAN 可以划分不同的用户到不同的工作组，同一工作组的用户也不必局限于某一固定的物理范围，网络构建和维护更加方便



### 路由器

> 俗称为三层交换机

![1649897675994](../img/1649897675994.png)

路由器是基于 IP 设计的，位于网络层，俗称三层网络设备。**路由器的各个端⼝都具有 MAC 地址和 IP 地址** 。 通常作为以太网中的发送方和接受方。路由器支持各种局域网和广域网的接口，主要用于互联局域网和广域网，实现不同网络间的通信。

路由器依靠IP地址寻址转发，路由器内有一份路由表，里面有它的寻址信息，当收到网络层的**数据报**后，会根据路由表和路由选择算法将数据报转发到下一站（可能是路由器、交换机、目的主机）

虽然路由器内集成了交换机的功能，主机与路由器相连也可以实现数据转发，但是不足之处是：路由器可扩展的接口不路交换机多，而且交换机通常由硬件加速转发，路由器主要靠软件寻址，速度慢。

![1649897477085](../img/1649897477085.png)

![1649898819646](../img/1649898819646.png)



# 三、传输层

**HTTP和RPC（远程过程调用）的区别：**

首先，**HTTP和RPC不是对等的概念**。

RPC是一个完整的远程调用方案，它包括了：通信协议+接口规范+序列化反序列化规范等。

而HTTP只是一个通信协议，工作在OSI的第七层，不是一个完整的远程调用方案。

如果拿HTTP+Restful规范+序列化与反序列化与RPC相比的话：

而在分布式系统中，因为每个服务的边界都很小，很有可能调用别的服务提供的方法。这就出现了服务A调用服务B中方法的需求，即远程过程调用。

最先想到的就是通过HTTP请求实现。例如服务B暴露Restful接口，然后让服务A调用它的接口。基于Restful的调用方式因为可读性好，但是有着明显的缺点，主要是效率低、封装调用复杂。当存在大量的服务间调用时，这些缺点变得更为突出。

服务A调用服务B的过程是应用间的内部过程，牺牲可读性提升效率、易用性是可取的。基于这种思路，RPC产生了。RPC通常会要求调用方中放置被调用的方法的接口，调用方只要调用了这些接口，就相当于调用了被调用方的实际方法，不用封装参数名和参数值等操作，十分易用。

**实现过程：**

动态代理接收到调用后，应该想办法调用远程的实际实现。这包括下面几步：

- 识别具体要调用的远程方法的IP、端口
- 将调用方法的入参进行序列化
- 通过通信将请求发送到远程的方法中

这样，远程的服务就接收到了调用方的请求。它应该：

- 反序列化各个调用参数
- 定位到实际要调用的方法，然后输入参数，执行方法
- 按照调用的路径返回调用的结果

> 注：RPC只是对底层协议的封装，其实对具体的通信协议是啥并没有太多要求。可以是TCP、UDP，也可以是HTTP。
>
> 本质上，两者是**可读性和效率之间的抉择**，**通用性和易用性之间的抉择**。



 TCP(传输控制协议)、UDP(用户数据报协议 )

##  TCP 协议与 UDP 协议的特点(区别)

- 最大的区别就在于UDP是不可靠传输而TCP是可靠传输，TCP的可靠传输涉及流量控制、拥塞控制、ARQ协议和超时重传机制等。

  还有一些其他的区别比如：


- UDP支持一对一，一对多，多对一的交互通信，因而支持单播、广播，多播；而TCP只能是点到点通信

- TCP是面向字节流的，发送数据时以字节为单位，一个数据包可以拆分为若干组进行发送，而UDP是面向报文的，一个报文只能一次发完。

- TCP的首部开销比UDP的首部开销要大，TCP首部在没有使用「选项」字段时是 20 个字节，而UDP首部只有8个字节

- TCP 的数据大小如果大于 MSS ，则会在传输层进行分段。UDP 的数据大小如果大于 MTU ，则会在 IP 层进行分片。

  **附：单播，多播(组播)，广播的区别**

  单播：主机给每个目标主机一个广播包				

  多播 (组播)：主机给每一组主机发送一个广播包

  广播：主机发送一个广播包，所有主机都能收到

  ​




##  TCP和UDP的应用场景

50.TCP和UDP各自的应用，举例子

使用TCP还是UDP得看需求。

因为TCP面向连接，并且能够保证数据的可靠交付，因此经常用于FTP文件传输，HTTP/HTTPS等。

例如，当想查看网页或查看电子邮件时，希望完整且按顺序查看网页，而不丢失任何内容。当下载文件时，希望获得的是完整的文件，而不仅仅是文件的一部分，因为如果数据丢失或乱序，都不是希望得到的结果，于是就用到了TCP。

但缺点是在用户量大的情况下服务端需要维护大量的连接，要承受很大的负荷。而且TCP有延迟发送机制，除非关闭相应的延迟确认算法，否则做不到实时。

而 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，所以经常用于

1.包总量较少的通信，如DNS等，发一个数据包就能把数据全部传完

2.视频、音频等多媒体通信，因为这些通信追求的是效率，数据包越快送达越好，而且即使丢失一两个数据包也不会造成太大影响。

3.广播，多播通信（因为TCP是点到点通信实现不了）



>  RUDP：在应用层类似于TCP，实现拥塞控制，流量控制，确认机制，重传机制。

## TCP 的端到端连接

网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路的一端称为一个socket。socket通常用来实现客户方和服务方的连接。socket是TCP/IP协议的一个十分流行的编程界面，一个socket由一个IP地址和一个端口号唯一确定。

客户端和服务端的通信方式主要有2种：

- Http通信
- WebSocket通信

WebSocket是HTML5规范提出的一种协议，它是封装在socket协议的上层协议。它是为了解决 客户端发起多个http请求服务器资源 必须要经过长时间轮询的问题而产生的，它能实现多路复用。两者的**最大差异**在于：

Http**连接使用的是**“请求-响应方式**”，即在**请求时建立连接通道**，当**客户端**向服务器**发送请求**后，**服务端**才能向客户端**返回数据。

**WebSocket**通信则是在双方**建立连接后**，可以**直接**进行**数据的传输**，在连接时可实现信息的**主动推送**，而**不需要**每次由**客户端**向服务器**发送请求**。

send函数在本质上并不是向网络上发送数据，而是将应用层发送缓冲区的数据拷贝到内核缓冲区中，至于数据什么时候会从网卡缓冲区中真正地发到网络中，要根据TCP/IP协议栈的行为来确定。

recv函数在本质上并不是从网络上收取数据，而是将内核缓冲区中的数据拷贝到应用程序的缓冲区中。在拷贝完成后会将内核缓冲区中的该部分数据移除。

![](../img/socket.png)


##  TCP 报文格式：

![](../img/tcp.png)

数据偏移占四位，指出TCP报文段的首部长度，最大为15，所以首部的最大长度为15 * 数据单位=15 * 4字节 = 60字节

##  UDP 报文格式：

![](../img/udp.jpg)





## 粘包问题     

> TCP根据对方给出的窗口值和当前网络的拥塞程度来决定一个报文段应包含多少个字节

**答：**UDP不会发生粘包，因为UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了2个字节也就是16位来表示UDP报文的长度，因此应用层能很好的将不同的数据报文区分开来，从而避免粘包和拆包的问题；而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块都看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，所以TCP在传输时才有可能发生粘包或者拆包。

TCP发生拆包原因：

- 要发送的数据大于MSS最大报文长度，或者大于TCP发送缓冲区剩余空间大小，TCP在传输前将进行拆包。

TCP发生粘包原因：

- 要发送的数据小于TCP发送缓冲区剩余空间大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

解决方案：

1.发送端给每个数据包添加的包首部中应该包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段来获得每个数据包的实际长度

2.发送端将每个数据包封装为固定长度，不够的可以通过补0来填充，这样接收数据端的应用层每次从缓冲区中读取固定长度的数据便可把每个数据包拆分开来。

3.可以在数据包中设置边界，比如添加特殊符号，这样接收数据端的应用层就可以通过这个边界将不同的数据包拆分开来

## 三次握手

### 介绍一下三次握手

> SYN(synchronous建立联机) ACK(acknowledgement 确认)  FIN(finish结束)

![](../img/threeHand.png)

- 三次握手的目的是建立可靠的通信信道，主要目的就是双方都确认自己与对方发送和接受都正常
- 刚开始客户端处于关闭状态，服务端处于监听状态
- 第一次握手，客户端将SYN置1，并随机产生一个初始序列号发送给服务端，进入SYN-send状态。这时服务端确认了对方发送正常
- 第二次握手，服务端以自己的SYN报文作为应答，将客户端的序列号加一作为ack的值，并随机产生一个自己的初始序列号发送给客户端，进入了SYN-RCVD状态，此时客户端确认了自己与对方发送与接受都正常，服务端确认了自己接受正常，对方发送正常。
- 第三次握手，客户端收到SYN报文后，会发送一个ACK报文，也是一样把服务端的序列号加一作为ack的值，表示收到了服务端的SYN报文，进入了establish状态。此时客户端和服务端都确认了自己与对方发送和接受都正常，这三次握手都缺一不可。
- accept



###  三次握手的原因

第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。设想一种情况：

如果客户端发送的连接请求在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

四次握手理论上可以，第二次握手的ACK和SYN分两次发送给客户端，就不合并成一次了；但是三次握手就足以保证通信的可靠性了，没有必要再握一次手

![1651545277224](../img/1651545277224.png)



##  四次挥手

### 介绍一下四次挥手

![](../img/forWave.jpg)

- 第一次挥手，客户端发送一个FIN，用来关闭客户端到服务端的数据传送

- 第二次挥手，服务端收到这个FIN，它发回一个ACK，确认序号为收到的序号加一。

- 此时客户端终止了数据发送，服务端还可以继续发送数据，待发送完后进行第三次挥手

- 第三次挥手，服务端关闭与客户端的连接，发送一个FIN给客户端。

  这两次挥手不能合并成一次是因为：当服务端收到FIN报文时，很有可能不会立即关闭连接，所以只能先回复一个ACK报文，进入了close_wait状态。等服务端端所有的报文都发送完了，才能发送FIN报文，因此中间挥了两次手

- 第四次挥手，客户端发回ACK报文确认，并将确认序号设置为收到的序号加一

- 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则也发出连接释放的通知，对方确认后就完全关闭了TCP连接





### 四次挥手的原因

- 因为TCP是双向对等传输，有两个方向的连接，需要2个FIN才能断开，每个FIN都需要一个ACK报文确认。

  ​


### 等待 2MSL 的原因

确保最后一个确认报文能够到达。如果最后一个确认报文丢失了，服务端没收到客户端发送的确认报文，那么就会重新发送连接释放请求报文，等待一段时间就是为了处理这种情况的发生。也就是为了让本次连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接释放请求报文。



### time_wait太多的原因

Time_wait 是主动关闭方收到FIN之后，发出ACK并开始Time_Wait等待。等待时间为2个MSL时间。

客户端一般不会出现大量TIME_WAIT的情况，如果出现了也造成不了什么影响。

而在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。这个场景下会出现大量socket处于TIME_WAIT状态。让服务器在短时间范围内同时占用大量有限的端口资源。、

注：端口有个0~65535的范围

解决办法：

1. time_wait 重用:允许将TIME-WAIT sockets重新用于新的TCP连接。（编辑内核文件/etc/sysctl.conf并使用命令让其失效）
2. 修改time_wait时间，比如修改为1MSL





##  TCP 可靠传输的工作原理

- 首先是应用数据被分割成TCP最适合发送的数据块，TCP给发送的每一个包进行排序，把有序的数据传送到应用层。

- 然后是检验和，TCP将保持它首部与数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化，收到的段的检验和有差错将会丢弃该报文。

- 最后是TCP的流量控制、拥塞控制、ARQ协议和超时重传机制等。

  ​



## ARQ协议

**停止等待ARQ协议：**每发送完一个分组就停止发送，等待对方确认，在收到确认之后再发送下一个分组。发送方如果在设定的时钟时间段内没有收到确认，就会认为发送的分组丢失，并重传发送的分组。停止等待协议是简单、可靠的协议；但是信道利用率太低。

**连续 ARQ 协议：**改进了停止等待ARQ协议这一缺点，滑动窗口就是连续ARQ的实现。

## 滑动窗口

- 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接受方会把自己的接受窗口数值放在窗口字段发送给对方，发送方根据这个值和网络拥塞程度来调整窗口大小
- 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到确认，那么发送窗口就会向右滑动一定的距离，直到左部第一个字节不是已发送并且收到了确认的状态。接收窗口类似，接收窗口左部字节已经确认并交付主机，就向右滑动一定距离，接收窗口只会对窗口内最后一个按序到达的字节进行确认。

  ​

##  流量控制

1. 流量控制是为了控制发送方的发送速率，保证接收方来得及接受，接受方发送的确认报文中的窗口字段rwnd可以用来控制发送方窗口的大小，从而影响发送方的发送速率。将窗口字段设置为0，则发送方不能发送数据。
2. 在双方停止发送数据时，为了避免互相等待的死锁局面一直延续，在接收到报文窗口字段值为 0 的一端，会设置一个持续计时器，每当持续计时器到期，会发送一个 0 窗口探测报文，如果对方会对这个报文确认并且给出窗口值，如果窗口值为 0 重新启动持续计时器，如果不为 0 可以重新发送数据。

注：接收方接收窗口满了，会把响应报文中的窗口字段设置为0，发送方收到后会停止发送数据。当接受方的应用程序读取了接收窗口的数据后，接收方会发送一个ACK报文提醒发送方可以发送数据了，但如果这个ACK报文丢失了就会造成死锁状态。



##  拥塞控制

- 拥塞控制是为了降低网络的拥塞程度，防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不至于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。为了进行拥塞控制，TCP的发送方要维持一个拥塞窗口的状态变量cwnd。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态改变。
- TCP 的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。

##  拥塞控制算法

- 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。所以慢开始是由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，只发送一个报文段，每经过一个传播轮次，cwnd 加倍增加。

- 拥塞避免： 在拥塞窗口大于慢开始门限后，就采用拥塞避免算法，具体的思路是让拥塞窗口 cwnd 按线性规律缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1，如果出现了超时，则令 慢开始门限为拥塞窗口cwnd的一半，然后重新执行慢开始。

  但是如果某个报文段在网络中意外丢失，但实际上网络并未发生拥塞。这时候发送方迟迟的收不到确认就会误认为网络发生了拥塞，让发送方错误的启动慢开始并把拥塞窗口又设置为了1，因而不必要的降低了网络传输效率。

- 快重传与快恢复：
  为了避免了这种情况，使用了快重传和快恢复算法，可以快速恢复丢失的数据包。如果接收方接收到一个不按顺序的数据段，本来接收方可以什么都不做，但按照快重传算法，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认报文指出的数据段丢失了，并立即重传这些丢失的数据段，提高了网络的吞吐量，并同时执行快恢复算法，快恢复算法会将慢开始门限和cwnd都设置为当前cwnd的一半，并开始执行拥塞避免算法 

**补充：** 发送方如何知道网络发生了阻塞：当网络发生阻塞时，路由器就要把来不及处理而排不上队的分组丢弃。因此只要发送方没有按时收到对方的确认报文，也就是发送方进行了超时重传，就判断网络出现了阻塞。

附：门限值单位是字节，只不过书上为了讲清原理用数据包个数来代替这样方便理解

![1659930107422](../img/1659930107422.png)



# 应用层

## 1 HTTP

**本质：** 一种浏览器与服务器之间约定好的通信格式。

###  HTTP 报文结构

HTTP 报文结构主要由 ` 起始行+首部+实体`   组成，首部和实体中间有个空行。

- 起始行：

  - 请求报文：请求方法 、请求URL、HTTP 协议及版本
  - 响应报文：HTTP协议及版本，响应状态码及状态描述 `HTTP/1.1 200 OK `

- 首部：

  格式为属性名：属性值

- 实体

  实体就是真实的数据，请求报文对应请求体，响应报文对应响应体。一般来说 get 请求没有请求体。


### HTTP首部（头）

首部按类型用途不同可以分为 5 类：

- 通用首部：请求报文和响应报文都可以使用的首部。

  ```
  Date: 日期                      #报文创建日期时间
  Connection: keep-alive/Uprade    #浏览器使用的连接类型
  Transfer-Encoding: chunked   #报文的传输编码方式
        (有如下编码方式：)
  	chunked：数据分块形式发送。
  	compress：采用 LZW (Lempel-Ziv-Welch)压缩算法。
  	deflate：采用 zlib 结构和 deflate 压缩算法。
  	gzip：采用 LZ77（Lempel-Ziv coding）压缩算法和 32 位 CRC 检验的编码方式。
  	identity：不压缩处理或修改
  ```

  ​

- 请求首部：请求报文使用，补充请求的附加内容、客户端信息、响应内容相关优先级等信息。

  ```
  Accept-Charset: utf-8    #告知服务器能发送哪些字符集
  Accept-Encoding: gzip, deflate    #告知服务器能发送哪些编码方式
  Host: test.test.com:8080  #提供接受请求的服务器主机号和端口号(如果是标准端口即可忽略)
  Referer: https://www.baidu.com/   #当前文档的 URL
  ```

  ​

- 响应首部：服务端向客户端返回响应报文中所使用的字段。补充响应的附加内容，也要求客户端提供额外的内容信息。

  ```
  Age: 20   #资源在代理缓存中存在的时间，单位为秒
  Location: http://www.baidu.com/test.html  #引导客户端访问另一个URL,通常配合3xx响应,提供重定向URL
  Server: Apache/2.4.38   #告知客户端当前服务器安装的应用程序信息
  Retry-After: 120   #告知客户端多久（具体日期或秒数）后再发送请求，主要配合状态码 503服务器正忙或                       3xx Redirect 响应
  ```

  ​

- 实体首部：补充实体主体的更多信息，如主体长度或 MIME 类型。

  ```
  Content-Encoding: gzip   #用于对特定媒体类型的数据进行压缩。告知客户端要用的解压方式：gzip,                                 compress, deflate, identity, br
  Content-Length: 15000    #响应消息体长度，单位为字节
  Expires: Mon, 21 Sep 2020 02:16:21 GMT     #指定日期/时间，超过即表示已过期。如果 Cache-Control                                            设置了 max-age 和 s-max-age，那么 Expires 会被忽略
  Last-Modified: Mon, 21 Sep 2020 02:16:21 GMT  #该实体最后修改时间
  ```

  ​


- 常见非标准字段（自定义）：HTTP 首部字段可以自定义。

  ```
  响应首部：
  X-XSS-Protection: 1   #控制浏览器 XXS 防护机制开关：0（关闭 XSS 过滤）或（开启 XSS 过滤）
  请求首部：
  DNT: 1      #拒绝被精准广告跟踪：0 （同意被跟踪） 或 1 （不同意被跟踪）
  ```

  ​



###  HTTP 特点

1. 灵活可扩展。

   语义上自由，只规定基本格式，其他部分没有严格的语法限制。传输媒体多样，支持文本、图片、视频等任意数据。

2. 可靠传输。

   HTTP 协议基于可靠的传输层协议 TCP。(可以扩展 TCP 为何可靠)

3. 请求响应模式。

   HTTP 采用一方发送一方接收，并且有发送就会有响应的模式。

4. 无状态。

   每次 HTTP 请求都是独立的、无关的，并且默认不需要保留状态信息。

   ​

###  HTTP 缺点

- HTTP 的整个传输过程都是明文传输，传输的信息直接暴露给了外界，很容易被截取。

- 不验证通信方的身份，因此可能遭遇伪装。

- 无法验证报文的完整性，所以有可能已遭篡改

  ​


###  常见的请求方法有哪几种

- GET：常用于获取资源，是幂等的

- POST：常用于向表单提交数据，是非幂等的

  在用户注册功能上，每次提交都是创建一个新的用户账户，此时则用POST

- PUT：常用于更新数据，是幂等的

  比如用户修改密码，每次请求都只是覆盖原先的密码值，多次请求得到的效果是一样的，此时该用PUT

- DELETE：删除资源

- HEAD：获取资源的元信息，只请求资源的首部，一般是用来检查网页是否被修改，检查超链接的有效性等

- PATCH：常用于对资源进行部分修改

- OPTIONS（[ˈɒpʃnz] ）：查询指定的 URL 能够支持的请求方法。

- CONNECT：建立连接隧道，用于代理服务器。

- TRACE：常用于追踪请求到响应这个过程的传输路径。

> 总结：如果是更新，并不会产生新的数据，新的数据会覆盖老的数据，用put，如果是创建，会产生新的数据，则用post

###  GET 与 POST 区别*

- 作用不同，GET 一般用来从服务端获取资源、POST 一般用来向服务端提交数据
- 参数传递方式不同，GET 的参数一般是通过 ? 跟在 URL 后面的，多个参数通过 & 连接；POST 的参数一般是包含在 请求体 中
- 安全性不同，GET 请求参数直接暴露在 URL 上，所以 GET 不能用来传递敏感信息
- 编码方式不同，GET 请求只能进行 URL 编码,只能接受 ASCLL 字符；POST 支持多种编码方式,application/x-www-form-urlencoded、multipart/form-data。
- 缓存机制不同，GET 请求会被浏览器主动缓存，而 POST 需要手动设置；GET 请求参数会被完整保留在浏览器历史记录里，而 POST 的参数不会保留；GET 在浏览器回退时是无害的，而 POST 会再次提交请求。
- 从 TCP 角度来讲，GET 请求会把请求报文一次性发出，而大部分浏览器 POST 请求会分为两个 TCP 数据包，首先发送 header 部分，如果服务器响应 100 (表明继续操作)，然后发送 body 部分。


补充：

1. 为什么 post 是两个 tcp 包呢？

   先去检测一下服务器 能正常应答，然后再把数据携带过去，如果应答不了，就没有了第二步数据传输。 就好像送快递的先打个电话给你看看你在不在家，在的话再送过去，避免不必要的资源浪费。

2. GET 方法的 URL 长度限制

   HTTP 协议并没有明确规定 GET 请求的 URL 长度，而是浏览器即服务器对 URL 长度进行了限制。

   - IE：2083 字节
   - chrome：8192 字节
   - 其他：大于 8192 字节


> Http get方法提交的数据大小长度并没有限制，Http协议规范没有对URL长度进行限制。目前说的get长度有限制，是特定的浏览器及服务器对它的限制。




###  HTTP 响应状态码

**状态码**都是３位数字，分为５大类

- 1开头：信息性状态码，表示目前是协议处理的中间状态，还需要后续操作。

  - 100 Continue：常用于 POST 请求的第一个请求报文的响应，当服务器返回此状态码表示已收到请求的第一部分，正在等待剩余部分。
  - 101 协议切换(Switching Protocols)：表示**服务器**回应客户端升级协议的请求对协议进行切换。常用于在 HTTP 协议切换到 WebSocket 的时候，如果服务器同意变更，就会返回此状态码。

- 2xx：成功状态码，表示请求成功处理完毕。

  - 200 OK：服务器已成功处理了请求。

  - 204 No Content：请求已经成功处理，但是返回的响应报文不包含实体部分。

  - 206 Partial Content（[ˈpɑːʃl]）：常用在 HTTP**分块下载**和**断点续传**，会带上响应头字段 Content-Range

- 3xx：重定向状态码，表示需要进行附加操作以完成请求。

  - 301 永久性重定向：请求的网页已永久移动到新位置，服务器返回此响应时，会自动跳转到新的位置。例如网站从 HTTP 协议升级到 HTTPS 协议，这时候服务器就会返回 301 状态码，并且浏览器默认会作缓存优化，在第二次访问时自动访问重定向的 URL。

  - 302 临时性重定向：服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。

  - 304 Not Modified：常用于协商缓存中服务器通知客户端资源未修改，可以继续使用缓存中的资源。

- 4xx：客户端错误状态码，表示客户端请求报文有误。

  - 400 Bad Request：请求报文中存在语法错误，但并没有具体出错原因。
  - 401 Unauthorized：请求要求身份验证。对于需要登录的网页，服务器可能返回此响应。
  - 403 Forbidden：请求的资源服务器禁止访问。
  - 404 Not Found：服务器无法找到对应资源
  - 405 请求的方法服务器不支持使用。可以通过 OPTIONS 方法查询指定的 URL 能够支持的请求方法。

- 5xx：服务端错误状态码，服务器处理请求出错。

  - 500 服务器在执行请求时发生错误，具体原因未知。
  - 502 Bad Gateway：作为网关或代理角色的服务器，从上游服务器（如 tomcat、php-fpm）中接收到的响应是无效的。
    - 可能和php-fpm.conf配置文件中的max_children最大子进程数这个参数有关，在高并发的请求下，达到php-fpm最大响应数，后续的请求就会出现502错误，可以使用netstat命令查看当前连接数
    - 也可能和request_terminate_timeout单个请求的超时终止时间有关，当请求中止时，也会出现502错误
    - 还应该考虑下数据库，查看下数据库进程是否有大量的locked进程，数据库死锁导致超时，前端终止了继续请求，但是SQL语句还在等待释放锁，这时就要重启数据库服务了或kill掉死锁SQL进程了。
    - 最后是排查网关服务是否启动
  - 503 Service Unavailable：服务器暂时处于过载或进行停机维护，暂时无法响应服务。


> 499:Nginx状态码，表示客户端关闭链接（服务器端处理的时间过长，客户端“不耐烦”了，断开了链接。）



  **HTTP断点续传**：断点续传返回的状态码是206

> HTTP请求头Range字段，响应头content-range

  断点续传就是从文件上次中断的地方开始重新下载或上传，当下载或上传文件的时候，如果没有实现断点续传功能，那么每次出现异常或者用户主动的暂停，都会去重头下载，这样很浪费时间；所以断点续传的功能就应运而生了

  想要实现断点续传的功能，就需要客户端记录下当前的下载或上传进度，并在需要续传的时候通知服务端本次需要下载或上传的内容片段

  附：如果续传的过程中文件变化了，怎么判断呢？

  **答：**会有一个字段记录文件的最后修改时间，服务器会检查这个字段，如果不符合则会重新从头发送 (返回状态码200)

 

###  HTTP 传输定长和不定长(分块传输)的包体

- 定长的包体涉及到 Content-Length 字段，如果手动将该字段的值设置的比传输的内容小，那么多余的字段会直接截取。如果设置的比传输内容大，响应的内容会出现错误。

- HTTP 通过分块传输不定长包体

  需要在响应头设置 Transfer-Encoding: chunked，开启这个字段后默认会采用长链接，并且 Content-Length 字段会被忽略。

  可以通过手动设置 Connection 字段为 keep-alive 开启长连接。

###  HTTP 的大文件传输(范围请求)

HTTP 通过服务器的**范围请求**来支持大文件传输，服务器端需要设置响应头的字段为 `Accpet-Ranges: bytes` 表明服务器支持范围请求。

而对于客户端需要指定要请求哪一部分的内容，通过设置请求头的 `Range` 字段，格式为`bytes=x-y` 例如 0-499、500- 分别表示开始到第 499 个字节、从第 500 个字节到文件终点。

服务器收到请求后，会验证客户端请求的范围是否违法，如果越界返回 416 状态码；否则会读取相应的片段，并返回 206 状态码。同时服务器需要添加 `Content-Range` 字段。

单段请求返回的响应：

```js
HTTP/1.1 206 Partial Content
Content-Length: 10
Accept-Ranges: bytes
Content-Range: bytes 0-9/100  // 0-9表示请求的范围，100表示总资源大小

i am xxxxx
```

多段请求返回的响应：

```js
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000010101
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes


--00000010101
Content-Type: text/plain
Content-Range: bytes 0-9/96

i am xxxxx
--00000010101
Content-Type: text/plain
Content-Range: bytes 20-29/96

eex jspy e
--00000010101--

```

在 Content-Type 字段中指定了两个值，multipart/byteranges 表示请求是多段请求，而 boundary=00000010101 是响应体中的分隔符，并且在最后的分隔末尾添加上--。

###  HTTP 中表单数据的处理

表单的提交方式，一般使用 POST 将提交的数据放在请求体中，并且有两种不同的 Content-Type 取值：

- application/x-www-form-urlencoded
  - 数据会被编码成以 & 分隔的键值对
  - 字符以 URL 编码方式编码
- multipart/form-data
  - Content-Type 还会包含 boundary，由浏览器指定
  - 数据会分为多个部分，每个部分间通过 boundary 指定的分隔符分隔，最后的分隔符会加上--
  - 各部分均有 HTTP 头部描述子包体

一般表单的提交采用 multipart/form-data 而不是 application/x-www-form-urlencoded ，因为没有必要做 URL 编码，会增加耗时和空间的占用。

**常见的Content-Type：**

Content-Type用于定义网络文件的类型和网页的编码，决定文件接收方将以什么形式、什么编码读取这个文件

```
text/html  ：HTML格式
text/plain ：纯文本格式      
text/xml   ：XML格式

image/gif  ：gif图片格式    
image/jpeg ：jpg图片格式 
image/png  ：png图片格式

application/xml     ： XML数据格式
application/json    ： JSON数据格式
application/pdf     ： pdf格式  
application/msword  ： Word文档格式
application/octet-stream ： 二进制流数据（如文件下载）

application/x-www-form-urlencoded ： 

<form encType="">中默认的encType，
form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式）。
服务器收到的raw body会是，name=aaa&key=bbb。

multipart/form-data ： 表单上传文件

```



###  HTTP 缓存

（属于 Web 性能优化，也称为浏览器缓存）

**概念：** 通过复用缓存资源，减少了客户端等待时间和网络流量，同时也能缓解服务器端的压力。

**缓存失效：** 手动刷新(f5)、右键刷新，强缓存失效协商缓存有效。强制刷新(ctrl+f5)，强缓存、协商缓存失效。

- 涉及的参数

  - Expires，响应头，资源的过期时间
  - Cache-Control，请求/响应头，控制强缓存的逻辑。
  - If-Modified-Since，请求头，资源最近修改时间
  - Last-Modified，响应头，资源最近修改时间(配合 If-Modified-Since 使用)
  - Etag，响应头，资源标识，资源变化会导致 ETag 变化
  - If-None-Match，请求头，缓存资源标识(配合 Etag 使用)

- **强缓存**，强制直接使用缓存  

  服务器在每次向浏览器响应资源时，在响应头中设定资源的过期时间，只要过期时间未达到浏览器就直接使用缓存数据库中资源。在浏览器控制台的 network 选项中可以看到该请求返回 200 的状态码，并且 size 显示 from disk cache 或 from memory cache

  强缓存缺点： 如果服务器上更新了资源浏览器并不会拿到最新的资源

  ![1649836666826](../img/1649836666826.png)

- **协商缓存**，和服务器协商确认缓存能否使用

  客户端会先从缓存数据库拿到一个缓存的标识，然后向服务端验证标识是否失效，如果没有失效服务端会返回304，这样客户端可以直接去缓存数据库拿出数据，如果失效，服务端会返回新的数据。服务端判断失效是通过比较请求头里的 上次响应数据时资源的修改时间和服务器上的最近修改时间，上次修改时间是设置缓存时服务器告诉客户端的。

  ![1649836778417](../img/1649836778417.png)

  **缺点：**浏览器端可以随意 Exipres，导致缓存使用不精准；最近修改时间只能精确到秒(可能 a.js 在 1 秒内经常变动,并且 a.js 设置了无缓存)

###  如何让 HTTP 有状态！！！

#### Cookie

HTTP 为了实现有状态引入了 Cookie，本质上是浏览器中存储的一个很小的文本文件，内容以键值对的方式存储。向**同一个域名**下发送请求，都会携带相同的 Cookie ，服务器能通过 Cookie 拿到客户端的状态。在服务器中可以设置响应头的 Set-Cookie 字段对客户端写入 Cookie。在 Cookie 写入时便绑定了域名和路径，在发送请求前会对比请求的域名和路径是否匹配，不匹配请求头就不携带 Cookie。

Cookie 的有效期可以通过 **Expires**(过期时间[ɪkˈspaɪəz] ) 和 **Max-Age**(存活时间) 两个字段设置。如果cookie字段添加了**Secure** （ [sɪˈkjʊə(r)] ）就只能通过 HTTPS 传输 Cookie，如果 添加了了 **HttpOnly** ，则说明 Cookie 不能通过 js 访问(document.cookie)，只能通过 HTTP 协议传输（防止攻击）。

Cookie 存储容量小，上限为 4kb、安全缺陷，会有 xss、csrf 攻击。

![1651127567251](../img/1651127567251.png)

#### Session

Session 的主要作用就是通过服务端记录用户的状态，存储结构为ConcurrentHashMap。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。当服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。 在服务端保存 Session 的方法很多，最常用的就是存在 内存数据库redis 中。大部分情况下，通过在 Cookie 中附加一个 Session ID 来方式来实现 Session 跟踪。

###  长连接和短连接

- 长链接：客户端向服务端发起连接，服务端接受客户端连接，双方建立连接，客户端与服务端完成一次请求后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接可以省去较多的 TCP 建立和关闭的操作，减少浪费，节约时间。服务端有保活功能(防止长链接无数据交互长期不关闭)。客户端与服务端之间的连接如果一直不关闭的话，会随着客户端连接越来越多，迟早服务端会崩溃。

- 短连接：客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。信道利用率低。

  ​

###  URI 和 URL 的区别是什么

- URI(Uniform Resource Identifier) 是统一资源标志符，定位web上的每一种资源如：图片，视频，文档等，这里所谓的定位指的是web上的资源相对于主机server来说，存放在server上的详细路径
- URL是全球资源定位符的英文缩写，平时上网时在浏览器中输入的那个地址就是URL
- 虽然URI和URL都定义了资源是什么，但URL还定义了该如何访问资源。URL是一种具体的URI，它是URI的一个子集，它不仅唯一标识资源，而且还提供了定位该资源的信息。我个人理解的话，只要能唯一标识资源的就是URI，在URI的基础上给出其资源的访问方式的就是URL
- **补充：** URI 包括 URL 和 URN，URN 是统一资源名称，用来定义一个资源的名称
  ![](../img/url.png)



### URL详细内容

​     `http://www.aspx.com:8080/news/index.jsp?boardId=5&id=1#name`

- 协议部分：代表网页使用的协议，比如HTTP，HTTPS，FTP等
- 域名部分：也可以使用IP地址作为域名部分
- 端口部分：非必须，如果省略的话http则默认80端口，https则默认443端口
- 虚拟目录部分：非必须，看服务器项目有没有添加虚拟目录
- 文件名部分：访问项目文件的名称
- 参数部分：get请求携带的参数
- 锚部分：非必须，用于定位网页上的位置




### HTTP的发展

HTTP 有多个版本：目前主流的协议是HTTP1.1

http1.0 及以下使用短连接，TCP发送端发送完信息并接收到信息后就断开

http1.1 使用长连接，是**半双工通信**：按顺序一个一个发送和回复

http2.0 是**全双工通信**，第一个消息发送后不用等待接收就可立即发送第二个消息

![1648878268253](../img/1648878268253.png)

附：单工通信，半双工通信，全双工通信区别

单工通信：数据只能在一个方向上传输，同一时刻只能有一方接收或者发送消息，不能实现双向通信；如 电视，广播

半双工通信：允许数据在两个方向上传输，但是同一时刻只允许数据在一个方向上传输；如 对讲机

全双工通信：允许同一时刻数据在两个方向上同时传输；如 电话



**队头阻塞**：如果 HTTP 开启长链接，共用一个 TCP 连接，同一时刻就只能处理一个请求，如果一个请求耗时过长，其他请求就只能处于阻塞状态。

#### HTTP队头阻塞解决方法

HTTP 队头阻塞是由于 HTTP 的 `请求-应答` 模型导致的，HTTP 规定报文必须一发一收，因此上一个请求没有收到响应，则会阻塞队列中后续请求的发送。

1. 采用并发连接，对一个域名允许分配多个长链接，等同于增加了任务队列，也就不至于一个队伍的任务阻塞其他所有任务。例如 Chrome 浏览器支持并发 6 个长链接。

2. 域名分片，在一个域名下分出多个二级域名，并且它们指向同样的一台服务器，这样在多个域名下有多个长链接，能够并发的长链接数就更多了。

   ​

####  HTTP 1.0 和 HTTP 1.1 的主要区别

- HTTP1.0 中默认采用短连接、HTTP1.1 中默认采用长链接，即默认开启 Connection:keep-alive

- 新增了错误状态码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

- HTTP1.1 支持滑动窗口，所以可以使用管道网络传输，即在同一个TCP连接里，客户端可以发起多个请求，不必等待其回来就可以发送第二个请求，这样可以减少整体的响应时间。

- 还是会导致队头阻塞

  ​

####  HTTP2 的改进

   **与 HTTP1.1 区别：**

- 二进制分帧 (二进制协议)

  HTTP1.1 中，报文的头部必须是 ASCII 编码的文本，数据体可以是文本也可以是二进制。HTTP2 是完全的二进制协议，请求头部和请求体都是二进制。

  HTTP2 将原来 Header + Body 的报文格式拆分成了一个个二进制的帧，一个 HTTP2 连接上可以同时发送多个帧，用 `Headers` 头信息帧存放头部字段， `Data` 数据帧存放请求体数据，并且每个二进制帧可以设置优先级，让服务器优先处理重要的资源请求。

  二进制分帧层是处于应用层和传输层之间的中间层，所有信息都会从中经过转换。

- 数据流

  双方都可以给对方发送二进制帧，这种二进制帧的**双向传输的序列**，叫做`数据流(Stream)`。HTTP2 用 `数据流` 在一个 TCP 连接上进行多个数据帧的通信。

  二进制分帧实现了乱序发送，在每个帧上都有一个流标记，在接收方接收完毕，会按照标记位的拼接成一整条信息。因此发送方可以并行发送数据，接收方可以并行返回确定，无需按照顺序返回。

  乱序指的是 `不同 ID 的流` 是乱序的，但 `同一个 ID 的流` 的帧一定是按顺序传输的，二进制帧到达后对方会将 `Stream ID` 相同的二进制帧组装成完整的请求报文或响应报文。

- 多路复用

  HTTP 会存在`队头阻塞`的问题，通过 **并发连接** 和 **域名分配** 并没有从 HTTP 本身解决问题，只是增加了 TCP 连接。也会带来额外的问题，多条 TCP 连接竞争有限的带宽，优先级高的请求不能优先处理。

  HTTP2 的多路复用基于二进制分帧，二进制分帧后，服务器收到的将不是一个完整的 HTTP 请求报文，而是一堆乱序的二进制帧。这些二进制帧不存在先后关系，因此也就不会排队等待，也就没有 HTTP 队头阻塞的问题。并且多路复用也可以并行发送请求，无需等待前面的请求的响应。

- 头部压缩

  1. 头部会使用 gzip 或 compress 压缩后再发送；
  2. 支持 HTTP2 的浏览器和服务器会维护一份相同的静态表和动态表，以及内置一个哈夫曼编码表。

  静态表存储一些常见的头部，和一些常见的头部键值对。动态表初始时是空的，如果请求头头部字段命中静态表中的名称，那么就会将这份键值对加入到动态表中。这样下次请求或响应只需要用一个字节的 `索引号` 就可以表示，这个字节就是一个指向表中数据的地址。

  另外像 Cookie 字段的值就可以用哈夫曼编码，将所有出现的字符串加入到哈夫曼编码表，让多次出现的字符串的索引值尽可能短，传输时传输索引值，这样可以达到很高的压缩效率。

- 服务器推送

  HTTP2 中服务器不再是被动的接收请求，响应请求，它也能通过新建 `Stream` 向客户端发送消息。

  当 TCP 连接建立之后，如果浏览器请求一个 HTML 资源，服务器就可以在返回相应 HTML 资源的基础上将 HTML 中引用到的其他资源一起返回给客户端，减少客户端发送请求的次数。

  另外，如果浏览器有缓存服务器就可能发送不必要的数据浪费带宽，因此一般只有在对某资源第一次请求时实现服务器推送。

  服务器推送遵循同源策略。

  需要注意的是，HTTP2 下服务器主动推送的是静态资源，和 Websocket 以及 SSE 方式向客户端发送及时数据的推送是不同的。

####  TCP 队头阻塞

HTTP2 虽然解决了 HTTP 的队头阻塞问题，但并没有解决 TCP 的队头阻塞问题。

HTTP2 中将每个请求拆分成多个二进制帧，不同请求的二进制帧组合成 Stream，Stream 是 TCP 上的逻辑传输单元，这样 HTTP2 就达到了一条连接同时发送多个请求。

TCP 队头阻塞：在一条 TCP 连接上同时发送多个 Stream，假如此时第二个 Stream 的第三个二进制帧丢失，因为 TCP 的数据有严格的前后顺序，如果前面的数据没到达，就算后面的数据到达了也需要等待，这就造成了 TCP 阻塞。

####  基于 UDP 的 HTTP3

队头阻塞：因为 UDP 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条链接。

HTTP3 是基于 QUIC 层的应用层协议，只要是运行在 QUIC 是至上的 HTTP 协议就被称为 HTTP3。

HTTP3 对 TCP 的拥塞控制、流量控制做了改进将其应用在 UDP 上

拥塞控制

- 热拔插

  TCP 的拥塞控制策略需要在系统层面进行操作，HTTP 的拥塞控制在应用层操作，动态选择拥塞控制策略。

- 前向纠错

  一段数据被切分为 10 个包后，一次对每个包异或运算，异或运算结果作为前向纠错包与数据包一起传输，如果传输过程中有一个数据包丢失，那么可以根据剩余 9 个包以及前向纠错包推算出丢失的包的数据，也能用于校验数据正确性。

- 单调递增的 Packet Number

  使用 Packet Number 解决原始请求与超时重传请求 ACK 的歧义，例如一个包丢失了，那么它重传的包的 Packet 标识将是比原来的标识大的数。

- ACK Delay

  TCP 计算 RTT 没有考虑接收发收到数据和发送数据间的延迟，HTTP3 考虑了这段延迟。

- 更多的 ACK

  一般接收后回复都是发送一个 ACK，但每接收一个就返回一个 ACK 太麻烦了，所以采用了接收多个后再回复多个也就是 ACK BLOCK，TCP 采用了这样的机制，但是最多只能有 3 个 ACK BLOCK，HTTP3 最多可以有 256 个 ACK BLOCK。在丢包严重的网络下，更多 ACK BLOCK 可以减少重传次数。





###  HTTP 和 HTTPS 的区别*

   1.https需要拿到ca证书，用来解决非对称加密中公钥来源的不安全性。

   2.端口不一样，HTTP 默认 80端口、HTTPS 默认 443端口

   3.http是超文本传输协议，信息明文传输，https则是具有安全性的ssl加密传输协议

   4.HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握⼿之后，  还需进行 SSL/TLS4次的握手过程，才可进⼊加密报文传输

> 应用层和传输层起作用，对于应用层透明

###  HTTPS

HTTP 即 HTTP + SSL/TLS，HTTPS 协议需要在建立 TCP 连接后，进行 SSL 握手，客户端和服务端交换随机数确定会话密钥，在之后的数据通信中采用会话密钥进行加密(表示层)。

#### SSL 握手的流程

![1651545720653](../img/1651545720653.png)

1. 握手第一步是客户端向服务端发送 Client Hello 消息，这个消息里包含了一个客户端生成的随机数 **Random1**、客户端支持的加密套件（Support Ciphers）和 SSL  版本号等信息。

2. 第二步是服务端向客户端发送 Server Hello 消息，这个消息会从 Client Hello 传过来的加密套件里确定一份加密套件，这个套件决定了后续加密和生成摘要时具体使用哪些算法，另外还会生成一份随机数 **Random2**。

3. 客户端收到服务端传来的证书后，先从 CA 验证该证书的合法性，验证通过后取出证书中的服务端公钥，再生成一个随机数 **Random3**，再用服务端公钥非对称加密 **Random3** 生成 PreMaster Key发送给服务端。

4. 服务端并用自己的私钥解密，到此三个随机数生成完毕，客户端和服务端使用这三个随机数用同样的算法计算出一个**master secret**，紧接着根据这个**master secret**推导出**hash secret**和**session secret**。握手结束后的应用层**数据**通过session secret这个秘钥进行对称加密，而用**hash secret** 是为了验证数据是否篡改，发送方和接受方再用相同的hash secret秘钥对HTTP报文做一次运算生成MAC，然后比较两个MAC相等，相等证明数据没有被篡改。

   **注意：**前面两个随机数都是明文传输，只有第三个随机数采用非对称加密后再传输，因此 SSL 握手的安全性体现在**第三个随机数**。在 `2` 这个步骤中，公钥的存放如果不采用数字证书，可能会出现**中间人攻击**

#### 中间人攻击

中间人拿到服务端的公钥，保留在自己身上并替换为自己的公钥，重新发送给客户端。  
而客户端在收到请求拿到公钥后，便会用这个公钥加密自己要发送的东西发送给服务端。  
中间人截取了客户端的发送的加密数据，并用自己的私钥去解密，中间人修改客户端要发送  
的信息为有害的信息，并用一开始截取的公钥加密发送给服务端。服务端用自己的私钥去解密，  
并执行了中间人修改后的有害操作。

![](../img/midp.awebp)

解决这个问题的办法就是借助第三方公证机构，服务端将自己的公钥和自己的个人信息包装成一个证书，凡是收到这个证书的客户就能确定是服务端的公钥，再进行安全地传输。

#### 数字证书

不过这个证书仍然可能被篡改，这时候就需要使用 `数字签名`，服务端将个人信息及其他必要信息用`hash算法`生成一个 `数字摘要`，只要`数字摘要`的内容被修改，使用该算法生成的`数字摘要`就会发生巨大改变(所以数字签名中的信息是不肯被篡改的)。

然后公证处用自己的 `私钥` 对 `数字摘要` 进行加密，生成`数字签名`，最后将服务端的`原始信息`与`数字签名`合并为`数字证书`，之后每次服务器要给客户端发送公钥时，就发送自己的数字证书。

客户端收到数字证书后，从证书中拿到 `hash算法` 将数字证书上的服务端原始信息转化为 `数字摘要` ，再用公证处的公钥对数字签名进行解密，也生成一个 `数字摘要`，所以如果此时服务端的信息被篡改了 `数字摘要` 就会出现很大的变动，所以就解决了中间人攻击的问题。



注意：上面第二步服务器鉴别过程中，证书里面的内容其实就是**服务器的公钥**和**证书认证机构对该公钥的数字签名** (数字签名就是用私钥加密的数据，这个数据就是公钥；私钥加密公钥也可以解开)

浏览器得到证书后，用CA的公钥对其中的数字签名进行校验，看结果和公钥符不符合，符合就表明通信的对方确实是真实的

附：公钥存放在哪里？

**答：**公钥存放在服务器上，公钥可随意传播；

而证书理论上应该存放在CA服务器上，但是现在一般都是存放在服务端上，直接由服务端发送给客户端进行校验，因为如果存放在CA服务器上，那么客户端除了要与服务端建立连接外，还需要和CA服务器端建立连接，这样太麻烦



#### 对称加密和非对称加密

> 再看看混合加密，还有这2加密的场景

**对称加密：**

对称加密是指用来加密和解密的是同一个秘钥。其特点是加密速度快，但是秘钥容易被黑客截获，所以安全性不高。常见的有AES、DES算法。

**非对称加密：**

非对称加密是指用来加密和解密的是不同的秘钥，它们是成对出现的，称为公钥和私钥，知道其中一个秘钥是无法推导出另外一个秘钥的。用公钥加密的内容需要用私钥才能解密，用私钥加密的内容需要用公钥才能解密。非对称加密的特点是安全性高，缺点是加密速度慢。常见的有RSA算法。

**加密算法的性能取决于加密算法所进行的加解密运算**

对于对称加密，因为对称加密主要的运算是位运算，速度非常快，如果使用硬件来计算，速度会更快，拿AES对称加密算法为例，其运算本质上是移位和替换

非对称加密算法的计算一般都比较复杂，如RSA，它里面涉及到大数乘法，大数取模等运算，效率相比于位运算很低。

如果发送消息非常频繁，使用非对称加密的话就会对性能造成很大影响。所以在实际开发过程中通常是对称加密和非对称加密结合使用的。也就是对称加密的秘钥是用非对称加密后发送的，这样能保证对称加密的秘钥不被黑客截获，然后在发送业务数据时就用对称加密。这样既保证了安全性也保证了加密速度。

**案例场景讲解：**

张三要找人装修一个房子，原则是谁的出价便宜就给谁装修

采用对称加密的话，李四发给张三一个报价文件报价50万，然后用对称秘钥加密，如果在传输过程中被王五截取了，王五就能用私钥解密获取文件内容，然后就报价49万获得了张三这个活，这显然是不安全的。

而采用非对称加密的话，张三会生成一对秘钥，私钥自己保管，公钥公布出去，李四用这个公钥加密后发送途中，被王五获得，但王五解密不了因为没有私钥，私钥只有张三有，使用这提高了安全性。

**数字签名有什么用**

但非对称加密也不是绝对安全的，还需要使用数字签名。

王五截货了李四的报价文件，虽然不能解密获得里面文件的内容，但可以伪造一份李四的报价文件，然后加密后替换原来的报价文件。

采用数字签名的话，李四会生成一对非对称加密的秘钥，私钥自己保持，公钥发给张三。然后李四就将自己的报价文件通过摘要算法得到一个摘要(假设摘要是`aaa`)，再用自己的私钥`lisi1`加密这个摘要就得到了报价文件的数字签名，最后将加密的报价文件和数字签名一起发给张三，张三收到后先用李四发过来的公钥`lisi2`解密数字签名得到摘要`aaa`，然后用自己的私钥`zhangsan1`解密加密的文件得到报价源文件，然后对报价源文件进行摘要算法，看计算得到的结果是不是`aaa`，如果不是`aaa`的话就说明报价文件被篡改了。



#### 常见的几种加密算法

**答：**

1、非对称加密算法 RSA

`RSA` 加密算法是目前最有影响力的 **公钥加密算法** 。

非对称加密算法有两个密钥，这两个密钥完全不同但又完全匹配。只有使用匹配的一对公钥和私钥，才能完成对明文的加密和解密过程。

是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的，RSA加密算法是目前最具影响力的公钥加密算法，它是第一个能同时用于加密和数字签名的算法

RSA加密算法基于一个十分简单的数论事实：将两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥

2、对称加密算法 DES/3DES/AES

对称的快加密算法，加解密的过程是可逆的

**DES**（Data Encryption Standard）：对称加密算法，数据加密标准，速度较快，适用于加密大量数据的场合

DES 加密算法是一种 分组密码，以 64 位为分组对数据加密，它的 密钥长度 是 56 位，加密解密用同一算法

DES 加密算法是对 密钥 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次

**3DES**算法是基于 DES 的 对称算法，对 一块数据 用 三个不同的密钥 进行 三次加密，强度更高

**AES** 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现；这种加密算法是美国联邦政府采用的 区块加密标准

AES 本身就是为了取代 DES 的，AES 具有更好的 安全性、效率 和 灵活性

3、消息摘要算法 MD5

MD5：严格来说不算加密算法，只能说是摘要算法，属Hash算法一类。MD5算法对输入任意长度的消息进行哈希运算，产生一个128位的消息摘要 (16进制表示为32个字符)；

- 不可逆：相同数据的MD5值肯定一样，不同数据的MD5值不一样
- 压缩性：任意长度的数据，算出的MD5值长度都是固定的 (相当于超损压缩)
- 容易计算：从原数据计算出MD5值很容易
- 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。

**注：**MD5明文加密不安全，因为可以使用穷举法对密文进行穷举，最终得到一个和密文一样的字符串，从而得到明文的密码。可通过引进干扰项(salt，也称之为加盐)，就是先对密码加入一串字符串作为干扰项，然后进行MD5加密得到一个32位的字符串，这样即使别人暴力破解了，由于存在干扰项也不会知道原文密码



> 消息摘要算法通常是用来判断文件是否被篡改过。
>
> 数字签名：数字签名就是一个文件的摘要加密后的信息。数字签名是和源文件一起发送给接收方的，接收方收到后对文件的摘要用摘要算法加密，然后和数字签名中的摘要进行比对，两者不一致的话说明文件被篡改了。
>
> 数字证书：数字证书是一个经证书授权中心生成的文件，数字证书里一般会包含公钥、公钥拥有者名称、CA的数字签名、有效期、授权中心名称、证书序列号等信息。其中CA的数字签名是验证证书是否被篡改的关键，它其实就是对证书里面除了CA的数字签名以外的内容进行摘要算法得到一个摘要，然后CA机构用他自己的私钥对这个摘要进行加密就生成了CA的数字签名，CA机构会公开它的公钥，验证证书时就是用这个公钥解密CA的数字签名，然后用来验证证书是否被篡改。



#### https缺点

1.https握手阶段延时较高：由于在进行http会话之前还要进行SSL握手(就是SSL会话的建立)，因此https协议握手阶段延时增加

2.https部署成本高：一方面 https 协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用https协议需要进行加解密的计算，占用CPU资源较多，间接加重了服务器的负担，降低了用户的访问速度，所以对服务器配置数目要求高



#### 端口号表

| 名称    | 端口号  | 协议   |
| ----- | ---- | ---- |
| SMTP  | 25   | TCP  |
| DNS   | 53   | UDP  |
| HTTP  | 80   | TCP  |
| HTTPS | 443  | TCP  |
| MySQL | 3306 | TCP  |
|       |      |      |





## 2 **应用层**

### 主要协议

- HTTP：端口 80,TCP

- DNS：端口 53,UDP/TCP

- DHCP：端口 67/68,UDP

- FTP：端口 20/21,TCP

- TFTP(Trivial FTP,简单文件传输协议)：端口 53,TCP

- SMTP：端口 25,TCP

- TELNET：端口 23,TCP

- POP3(邮件读取协议)：端口 110,TCP

- IMAP(网际报文存取协议)：端口 143,TCP

  ​

### 输入 url 到显示主页的过程*  

- 首先是浏览器查询DNS，获取域名对应的IP地址：具体过程包括浏览器搜索自身的DNS缓存，搜索操作系统的DNS缓存、读取本地Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析（此解析具有权威性）。如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地DNS服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询。

- 浏览器获得域名对应的IP地址之后，浏览器向服务器请求建立连接，发起三次握手。

  握手时涉及到了报文的发送，网络层的路由器会通过路由选择算法内部维护一个路由表，通过查找路由表可以得下一跳的IP地址，然后通过ARP地址解析协议获得下一跳的MAC地址然后进行数据转发。

- TCP/IP链接建立起来后，浏览器向服务器发起HTTP请求。

- 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器。

- 浏览器解析并渲染视图，若遇到对js文件，css文件以及图片等静态资源的应用，则重复上述步骤完并向服务器请求这些资源。

- 浏览器根据其请求到的资源，数据渲染页面，最终向用户呈现一个完整的页面。


![1651545623225](../img/1651545623225.png)



**为什么会进行url解析？**

因为网络标准规定了URL只能是字母和数字，还有一些其它特殊符号。如果不转义会出现歧义，比如url后面的参数是key=value,假如value的值本身就含有=或者&，服务端就会解析成2个键值对，出现了歧义。

![1649831233236](../img/1649831233236.png)

还有一种原因是URL只能使用ASCLL字符集来通过因特网进行发送，由于URL常常会包含 ASCII 集合之外的字符，URL 必须转换为有效的 ASCII 格式。编码后会使用%其后跟随两位的十六进制数来替换非Ascll字符。相当于使用没有特殊用途或者特殊意义的可打印字符去表示那些不安全的字符。



###  DNS 解析域名获取 IP 地址

![](../img/dns.png)



#### 递归查询和迭代查询：

- 本地DNS服务器以客户机的身份向其他域名服务器查询的过程属于递归查询。其他域名服务器再向网域内的域名服务器查询直到得到最终的IP地址告诉本机，而不是让主机自己进行下一步查询。
- 迭代查询是本地域名服务器向那13个根域名服务器查询，不在的话就告诉顶级域名服务器的ip地址让本地dns服务器去查询、又不在的话就告诉二级域名服务器的ip地址让本地dns服务器去查询。这个查询的过程就是迭代查询，最后找到了需要解析的 ip 地址就把这个结果返回给查询该域名的主机。



（注：由于DNS报文总大小为512字节限制，所以只有13个根域名服务器）

![1648878138891](../img/1648878138891.png)



#### 本地域名服务器向根服务器查询的是什么？

**答：**根服务器不负责具体的域名解析，但是根服务器知道每个具体的域名解析的服务器的地址，即知道.com域名是由哪个服务器来进行解析，.org，.edu又是由哪些服务器进行解析

所以本地域名服务器向根服务器查询的是其他DNS服务器的地址





# Web问题解决与防范

## 跨域问题

CORS全称Cross-Origin Resource Sharing，意为跨域资源共享。跨域是指绕过浏览器**同源策略**约束请求资源的方式。当一个资源去访问另一个**不同域名**或者**同域名不同端口**的资源时，就会发出跨域请求。如果此时另一个资源不允许其进行跨域资源访问，那么访问的那个资源就会遇到跨域问题。

在实际应用中，我们常常会遇见的前后端是不属于同源，这时候便需要我们实现跨域访问。

跨域是浏览器的一种机制！所以只要我们关闭了浏览器这个机制，就能巧妙的规避了这个问题。（新建空白文件夹用命令行注入参数）。

但我们不可能让用户适应我们的要求而修改浏览器的配置，而且这样也超级不安全。

最常见的方式是通过后端修改http响应头，允许服务器标示浏览器开放使用除了它自己以外的其它不同源资源数据。也就是在响应头设个：设个 Access-Control-Allow-Origin: *

前端：

![1650854741052](../img/1650854741052.png)

后端：

![1650854773811](../img/1650854773811.png)



## 浏览器的同源政策

两个网页"同源"。所谓"同源"指的是"三个相同"：

- 协议相同
- 域名相同
- 端口相同

同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据。防止XSS(跨站脚本攻击)、CSRF(跨站请求伪造) 等攻击。

设想这样一种情况：A网站是一家银行，用户登录以后，又去浏览其他网站。如果其他网站可以读取A网站的 Cookie，会发生什么？

很显然，如果 Cookie 包含隐私（比如存款总额），这些信息就会泄漏。更可怕的是，Cookie 往往用来保存用户的登录状态，如果用户没有退出登录，其他网站就可以冒充用户，为所欲为。因为浏览器同时还规定，提交表单不受同源政策的限制。

限制范围：

（1） Cookie、LocalStorage 和 IndexDB 无法读取。

（2） DOM 无法获得。

（3） AJAX 请求不能发送。

**LocalStorage 详解：**

生命周期：除非被手动清除，否则将会永久保存

存放数据大小：可以保存5MB的信息

http请求：仅在客户端（即浏览器）中保存，不参与和服务器的通信

localStorage只要在相同的协议、相同的主机名、相同的端口下，就能读取/修改到同一份localStorage数据。

![localstorage](../img/localStorage .awebp)



## 代理

### 正向代理

正向代理是一个位于客户端和目标服务器之间的代理服务器（中间服务器）。为了从目标服务器取得内容，客户端向代理服务器发送一个请求，**并且指定目标服务器**，之后代理向目标服务器转发请求，将获得的内容返回给客户端。

正向代理是**代理客户端**，为客户端收发请求，使真实客户端对服务器不可见。

![1663637999656](../img/1663637999656.png)

用途：

- **突破访问显示**：通过代理服务器，可以突破自身ip访问限制，访问国外网站等
- **提高访问速度**：通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时，则直接由缓冲区中取出信息，传给用户，以提高访问速度
- **隐藏客户端真实ip**：上网者可以通过正向代理的方法隐藏自己的ip，免受攻击

### 反向代理

反向代理是指以代理服务器来接收客户端的请求，然后将请求转发给内部网络上的服务器，将从服务器上得到的结果返回给客户端，此时代理服务器对外表现为一个反向代理服务器。

反向代理是**代理服务器**，为服务器收发请求，使真实服务器对客户端不可见。

![1663638146793](../img/1663638146793.png)

- **隐藏服务器真实ip**：使用反向代理，可以对客户端隐藏服务器的ip地址
- **负载均衡**：反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上
- **提高访问速度**：反向代理服务器可以对静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度
- **提供安全保障**：反向代理服务器可以作为应用层防火墙，为网站提供对基于web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。



## 网络中常见的攻击有哪些？

**答：**网络攻击主要分为被动攻击和主动攻击（计网P324）

被动攻击是指攻击者从网络上窃取他人的通信内容；通常把这类攻击叫做截获；在被动攻击中，攻击者通常只是观察和分析某一个协议数据单元 (PDU) 而不干扰信息流

主动攻击有以下三种方式

1.篡改：攻击者故意修改网络上的报文再发送给接收方

2.恶意程序：包括病毒，木马，流氓软件等

3.拒绝服务攻击 (Dos攻击)：指攻击者向互联网上的某个服务器不停的发送大量数据分组，使得该服务器无法正常提供服务，甚至完全瘫痪；若是从互联网的成百上千的网站集中攻击一个网站，则称为分布式拒绝服务攻击 (DDos攻击)

总结：被动攻击一般检测不出来，主动攻击可采取适当措施防范



**附：避免SYN攻击的几种方式 （小林266）**

**答：**服务端的 Socket 会在内核中维护两个队列，一个称为半连接队列 (也叫SYN队列)，这里面的连接都是还没有完成三次握手的连接，另外还有一个全连接队列 (Accept 队列)，这里面的连接都是已经完成三次握手的连接

**方法一：**其中⼀种解决方式是通过修改 Linux 内核参数，控制半连接队列大小和当队列满时应做什么处理，比如队列满时直接对新到来的连接发送 RST 包，不允许建立连接；但是这种方式实现比较困难，因为修改内核参数想再使其生效需要重新编译 Linux 内核

**方法二：**如果不断受到 SYN 攻击，则很容易导致半连接队列被占满，当半连接队列满时，后续的数据包不再进入半连接队列

TCP 有一个 syncookie 功能，当开启了 syncookie 就可以在不使用半连接队列的情况下成功建立连接

syncookie 服务器根据当前状态计算出⼀个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报⽂时，取出该值验证，如果合法，就认为连接建⽴成功，将连接放入accept 队列中

syncookie 参数主要有以下三个值：

0值：表示关闭该功能；	1值：表示仅当SYN半连接队列满时，再启动 syncookie，所以防御 SYN 攻击可以将该参数设置为1

2值：表示无条件开启该功能

**方法三：**减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接；那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开



**附：常见的几种web攻击**

简单的 HTTP 协议本身并不存在安全问题，因此协议本身几乎不会成为攻击的目标；而应用 HTTP 协议的服务器和客户端，以及运行在服务器上的Web应用等资源才是攻击的目标。

目前来自互联网的攻击大多都是冲着Web站点来的，它们把 Web 应用作为攻击目标

### XSS

> （Cross-Site Scripting）跨站脚本攻击

XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。

XSS 的本质是：恶意代码未经过滤，与网站正常的代码混在一起；浏览器无法分辨哪些脚本是可信的，导致恶意脚本被执行。

而由于直接在用户的终端执行，恶意代码能够直接获取用户的信息，或者利用这些信息冒充用户向网站发起攻击者定义的请求。

在部分情况下，由于输入的限制，注入的恶意脚本比较短。但可以通过引入外部的脚本，并由浏览器执行，来完成比较复杂的攻击策略。

**预防**：

- 服务端转义字符

- HEAD 设置 X-XSS-Protection

- 设置HttpOnly Cookie 防止被客户端窃取cookie

  ​

### CSRF

> （Cross-site request forgery）跨站请求伪造
>
> 07年Gmail一个用户点开了一个黑客的链接，所有邮件都被窃取，就是靠的CSRF攻击

攻击者诱导受害者在进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。

一个典型的CSRF攻击有着如下的流程：

- 受害者登录a.com，并保留了登录凭证（Cookie）。
- 攻击者引诱受害者访问了b.com。
- b.com 向 a.com发送了一个请求：a.com/act=xx
- a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。
- a.com以受害者的名义执行了act=xx。
- 攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让a.com执行了自己定义的操作。

几种常见的攻击类型：

- get类型

  GET类型的CSRF利用非常简单，只需要一个HTTP请求，一般会这样利用：

  ```
   <img src="http://bank.example/withdraw?amount=10000&for=hacker" > 
  复制代码
  ```

  在受害者访问含有这个img的页面后，浏览器会自动向

  ```
  http://bank.example/withdraw?account=xiaoming&amount=10000&for=hacker
  ```

  发出一次HTTP请求。bank.example就会收到包含受害者登录信息的一次跨域请求。

- post类型

  这种类型的CSRF利用起来通常使用的是一个**自动提交的表单**，如：

  ```
   <form action="http://bank.example/withdraw" method=POST>
      <input type="hidden" name="account" value="xiaoming" />
      <input type="hidden" name="amount" value="10000" />
      <input type="hidden" name="for" value="hacker" />
  </form>
  <script> document.forms[0].submit(); </script> 
  复制代码
  ```

  访问该页面后，表单会自动提交，相当于模拟用户完成了一次POST操作。

  POST类型的攻击通常比GET要求更加严格一点，但仍并不复杂。任何个人网站、博客，被黑客上传页面的网站都有可能是发起攻击的来源，后端接口不能将安全寄托在仅允许POST上面。

- 链接类型的CSRF

  链接类型的CSRF并不常见，比起其他两种用户打开页面就中招的情况，这种需要用户点击链接才会触发。这种类型通常是在论坛中发布的图片中嵌入恶意链接，或者以广告的形式诱导用户中招，攻击者通常会以比较夸张的词语诱骗用户点击，例如：

  ```
    <a href="http://test.com/csrf/withdraw.php?amount=1000&for=hacker" taget="_blank">
    重磅消息！！
    <a/>
  ```

  由于之前用户登录了信任的网站A，并且保存登录状态，只要用户主动访问上面的这个PHP页面，则表示攻击成功。

**防护策略：**

- 由于CSRF通常是从第三方网站发起，所以我们可以进行**同源检测**，使用HTTP头中的**Referer字段**，但这种方法并非万无一失，因为Referer的值是由浏览器提供的，把安全性都依赖于第三方浏览器来保障并不是很安全，在部分情况下，攻击者可以隐藏，甚至修改自己请求的Referer。所以遇到referer不存在的情况应该直接阻止，特别是没用使用第二层防护措施的情况下。

- 第二层防护措施是使用**CSRF Token**，因为在CSRF攻击中，攻击者无法直接窃取到用户的信息，仅仅是冒用Cookie中的信息。所以我们可以要求所有用户请求都携带一个CSRF攻击者无法获取到的Token。服务器通过校验请求是否携带正确的Token，来把正常的请求和攻击的请求区分开，也可以防范CSRF的攻击。

  原理：

  - get请求时给用户生成一个Token并加密后存放在Session，Token包括随机字符串和时间戳的组合，

  - 页面提交的请求携带这个Token

    ```
    get:
     http://url?csrftoken=tokenvalue
    post
     form 的最后加上:
      <input type=”hidden” name=”csrftoken” value=”tokenvalue”/>
    ```

  - 服务端验证Token是否正确

    判断有效性然后对比正确性

    ​





### SQL注入

SQL注入攻击是指针对 web 应用使用的数据库，通过运行非法的 SQL语句 而产生的攻击；web 应用通常都会用到数据库，当需要对数据库中的表进行增删改查操作时，会使用 SQL 语句连接数据库进行特定的操作；如果在调用 SQL 语句的方式上存在疏漏，就有可能执行被恶意注入的非法 SQL 语句

**实例：**

```
' "+userName+" ' and password=' "+password+" '";
```

当输入了上面的用户名和密码，上面的SQL语句变成：

```
SELECT * FROM user_table WHERE username=
'’or 1 = 1 -- and password='’
```

or 1=1表示一定成功，而且后面用--把后面语句注释

```
SELECT * FROM user_table WHERE
username='' ;DROP DATABASE (DB Name) --' and password=''
```

这种情况后果可想而知！

**解决策略：**

1、像账号、密码、邮箱、日期这种有固定格式的变量在sql执行前应该按照固定格式检查。

2、像文章发布、评论系统等这种无法确定固定格式的变量，一定要进行特殊符号过滤或转义处理。

3、绑定变量使用预编译语句是预防SQL注入的最佳方式，使用预编译的SQL语句语义不会发生改变，在SQL语句中，变量用问号?表示，黑客即使本事再大，也无法改变SQL语句的结构



### DDos攻击*

> (Distributed Denial of Service)即分布式拒绝服务攻击

目前最为强大、最难以防御的攻击方式之一

两个常见的DDos手段：

- SYN Flood（syn泛洪攻击）

  TCP协议为实现可靠传输，在三次握手的过程中设置了 一 些异常处理机制。第三步中如果服务器没有收到客户端的ACK报文，服务端一般会进行重试，也就是再次发送 SYN +ACK 报文给客户端，并且一 直处于 SYN_RECV 状态，将客户端加入等待列表。重发一 般会进行 3-5次，大约每隔30秒左右会轮询一 遍等待队列，重试所有客户端；另一 方面，服务器在发出SYN+ACK报文后，会预分配 一 部分资源给即将建立的TCP 连接，这个资源在等待重试期间－直保留，更为重要的是，服务器资源有限，可以维护的等待列表超过极限后就不再接收新的SYN报文，也就是拒绝建立新的TCP连接。

  SYN Flood正是利用了TCP协议三次握手的过程来达成攻击的目的。攻击者伪造大量的IP地址给服务器发送SYN报文，但是由于伪造的IP地址几乎不可能存在，也就不可能从客户端得到任何回应，服务端将维护一 个非常大的半连接等待列表，并且不断对这个列表中的IP 地址进行遍历和重试，占用了大量的系统资源。更为严重的是，由于服务器资源有限，大量的恶意客户端信息占满了服务器的等待队列，导致服务器不再接收新的SYN请求，正常用户无法完成三次握手与服务器进行通信，这便是SYN Flood攻击。

- DNS Query Flood（dns解析泛洪攻击）

  向被攻击的服务器发送海量的域名解析请求，解析的域名通过伪造端口和客户端IP，防止被过滤。被攻击的DNS服务器在接收到域名解析请求后，首先会在服务器上查找是否有对应的缓存，由于域名是随机生成的，几乎不可能有相应的缓存信息，当没有缓存。 该域名无法直接由该DNS服务器进行解析时，DNS服务器会向其上层DNS服务器递归查询域名信息，直到全球互联网的13台根DNS服务器。大量不存在的域名解析请求给服务器带来很大的负载，当解析请求超过一定量时，就会造成 DNS 服务器解析域名超时，这样攻击者便达成了攻击目的。





3.OS 注入攻击是指通过 web 应用，执行非法的操作系统命令达到攻击的目的；只要是在能调用 shell 的函数的地方就存在被攻击的风险；可以从 web 应用中通过shell 调用操作系统命令，倘若调用 shell 时存在疏漏，就可以执行插入的非法 OS 命令

4.HTTP 首部注入攻击是指攻击者通过在响应首部字段插入换行，添加任意响应首部或主体的一种攻击





# 应用程序访问量过大

应用程序访问量过大崩溃可能原因：

- 服务器内存不足，每次应用线程都会占用一定的内存空间，请求越多内存用量越大，而且还有日志文件也会占用内存很大的一份空间。
- 服务器超载，可能达到了线程池的最大连接数量。或者是因为设计上的局限性，高并发量造成了缓存穿透，缓存雪崩，造成了服务器宕机。



解决办法：

- 采用Nginx进行限流

  Nginx的”流量限制”使用漏桶算法(leaky bucket algorithm)，该算法在通讯和分组交换计算机网络中广泛使用，用以处理带宽有限时的突发情况。就好比，一个桶口在倒水，桶底在漏水的水桶。如果桶口倒水的速率大于桶底的漏水速率，桶里面的水将会溢出；同样，在请求处理方面，水代表来自客户端的请求，水桶代表根据”先进先出调度算法”(FIFO)等待被处理的请求队列，桶底漏出的水代表离开缓冲区被服务器处理的请求，桶口溢出的水代表被丢弃和不被处理的请求。

- 降级

  降级也就是服务降级，当我们的服务器压力剧增为了**保证核心功能的可用性** ，而**选择性的降低一些功能的可用性，或者直接关闭该功能**。这就是典型的**丢车保帅**了。就比如贴吧类型的网站，当服务器吃不消的时候，可以选择把发帖功能关闭，注册功能关闭，改密码，改头像这些都关了，为了确保登录和浏览帖子这种核心的功能。

  一般而言都会建立一个独立的降级系统，可以灵活且批量的配置服务器的降级功能。当然也有用代码自动降级的，例如接口超时降级、失败重试多次降级等。具体失败几次，超时设置多久，由你们的业务等其他因素决定。开个小会，定个值，扔线上去看看情况。根据情况再调优。


- 熔断

  **降级一般而言指的是我们自身的系统出现了故障而降级。而熔断一般是指依赖的外部接口出现故障的情况断绝和外部接口的关系。**

  例如你的A服务里面的一个功能依赖B服务，这时候B服务出问题了，返回的很慢。这种情况可能会因为这么一个功能而拖慢了A服务里面的所有功能，因此我们这时候就需要熔断！即当发现A要调用这B时就直接返回错误(或者返回其他默认值啊啥的)，就不去请求B了。我这还是举了两个服务的调用，有些那真的是一环扣一环，出问题不熔断，那真的是会雪崩。

- 限流

  一般限制的指标有：**请求总量或某段时间内请求总量**。

  请求总量：比如秒杀的，秒杀100份产品，我就放5000名进来，超过的直接拒绝请求了。

  某段时间内请求总量：比如规定了每秒请求的峰值是1W，这一秒内多的请求直接拒绝了。咱们下一秒再见。